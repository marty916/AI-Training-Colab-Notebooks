{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNP3Dr6kWWQNGhwKFJNuTsj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marty916/AI-Training-Colab-Notebooks/blob/main/IBM-SkillsBuild-Program-in-Artificial-Intelligence/Session2_Regression_Clustering_Classification_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### NumPy, short for \"Numerical Python,\" is a powerful library used in Python programming for numerical and scientific computing. It's like a supercharged version of Python's built-in list data structure, designed to handle large amounts of data more efficiently.\n",
        "\n",
        "### Matplotlib is a powerful library in Python used for creating visualizations, such as graphs and charts. It’s particularly useful for data scientists, engineers, and anyone who needs to visualize data to understand and communicate trends, patterns, and insights.\n",
        "\n"
      ],
      "metadata": {
        "id": "DbTvKgpCjf6w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYXUX2wDTvhQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate some data\n",
        "np.random.seed(0)\n",
        "X = 2 * np.random.rand(100, 1)\n",
        "y = 4 + 3 * X + np.random.randn(100, 1)"
      ],
      "metadata": {
        "id": "-W2s9hIzkIC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BxhBUPcJlFJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Regression implementation\n",
        "X_b = np.c_[np.ones((100, 1)), X]  # add x0 = 1 to each instance\n",
        "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
        "\n",
        "print(\"Best parameters (theta):\", theta_best)"
      ],
      "metadata": {
        "id": "MARySy9kkKf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "X_new = np.array([[0], [2]])\n",
        "X_new_b = np.c_[np.ones((2, 1)), X_new]\n",
        "y_predict = X_new_b.dot(theta_best)\n",
        "\n",
        "plt.plot(X_new, y_predict, \"r-\", label=\"Best Fit Line\")\n",
        "plt.plot(X, y, \"b.\", label=\"Data Points\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.title(\"Linear Regression\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_CDRqSEXkNBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification with Scikit-learn\n",
        "\n",
        "### Scikit-learn is a popular Python library for machine learning, offering simple and efficient tools for data analysis and modeling. It provides a wide range of algorithms for classification, regression, clustering, and dimensionality reduction. The library integrates well with other scientific libraries like NumPy and pandas, making it easy to build and evaluate machine learning models. Scikit-learn is widely used for its ease of use, comprehensive documentation, and versatility in handling different machine learning tasks."
      ],
      "metadata": {
        "id": "KAYQ-r1fjwD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ],
      "metadata": {
        "id": "gTvKz9ifj1uD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### iris is a dataset included in the Sckikit-learn library. Used frequently for beginner's introduction.\n",
        "\n",
        "\n",
        "*   150 samples from three species of Iris flowers\n",
        "*   Each sample has four features: sepal length, sepal width, petal length, and petal width, all measured in centimeters\n",
        "\n"
      ],
      "metadata": {
        "id": "onWw1EIVAqde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris[\"data\"][:, 3:]  # petal width\n",
        "# Use the built-in 'int' instead of 'np.int'\n",
        "y = (iris[\"target\"] == 2).astype(int)  # Iris-Virginica"
      ],
      "metadata": {
        "id": "mQHUpzPB_9vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6sbxms8CzJCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
        "y_proba = model.predict_proba(X_new)\n",
        "\n",
        "plt.plot(X_new, y_proba[:, 1], \"g-\", label=\"Iris-Virginica\")\n",
        "plt.xlabel(\"Petal width\")\n",
        "plt.ylabel(\"Probability\")\n",
        "plt.legend()\n",
        "plt.title(\"Logistic Regression\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lfCMX-IwADJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "mz4O8oP4j5xM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8Yk41_17j97T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate some data\n",
        "X = np.random.rand(100, 2)"
      ],
      "metadata": {
        "id": "n1U0fgLTCyN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Mean Clusering\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Imagine you have a big jar of different types of candies, and you want to sort them into separate groups based on their colors. K-Means Clustering is like a smart way of sorting candies into different groups."
      ],
      "metadata": {
        "id": "fI6f8gNTC_0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Means Clustering\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(X)\n",
        "y_kmeans = kmeans.predict(X)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
        "plt.title(\"K-Means Clustering\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FCnVkyD6C2yZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hierarchical Clustering\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Imagine you have a big box of mixed Lego pieces, and you want to organize them into groups based on their shapes and colors. Hierarchical Clustering is like a way of organizing these Lego pieces step by step, either by starting small and building up or starting big and breaking down.\n",
        "\n",
        "\n",
        "*   Agglomerative (Bottom-up) - Starting small, think of this as starting with one Lego piece as its own group\n",
        "*   Divisive (Top-down) - Starting big, think of this as starting with the whole box of Lego pieces as one big group\n",
        "\n",
        "*Note: Scikit-learn does not have built-in implementation for divisive clustering (possibly use SciPy)*\n",
        "\n"
      ],
      "metadata": {
        "id": "fhkWdnYODOko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hierarchical Clustering\n",
        "hc = AgglomerativeClustering(n_clusters=3)\n",
        "y_hc = hc.fit_predict(X)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_hc, s=50, cmap='viridis')\n",
        "plt.title(\"Hierarchical Clustering\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "GSY_Mvn-C5j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DBSCAN\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Imagine you’re in a playground filled with different groups of kids playing different games, and you want to figure out who is playing with whom. DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is like a smart way of finding these groups based on how close the kids are to each other and how many kids are nearby."
      ],
      "metadata": {
        "id": "g746XDACEXTw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DBSCAN Clustering\n",
        "dbscan = DBSCAN(eps=0.1)\n",
        "y_dbscan = dbscan.fit_predict(X)\n",
        "\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_dbscan, s=50, cmap='viridis')\n",
        "plt.title(\"DBSCAN Clustering\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UTmkyHjXC73O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommender Systems"
      ],
      "metadata": {
        "id": "1VARKLrgkBcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ],
      "metadata": {
        "id": "5mGsmU4MkFni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "data = {'user_id': [1, 1, 1, 2, 2, 3, 3, 4, 4, 4],\n",
        "        'item_id': [1, 2, 3, 2, 3, 1, 4, 2, 3, 4],\n",
        "        'rating': [5, 4, 3, 5, 4, 4, 5, 5, 4, 4]}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "u_ac4pIBFHsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (df)"
      ],
      "metadata": {
        "id": "WNr5NSAX2JIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create user-item matrix\n",
        "user_item_matrix = df.pivot_table(index='user_id', columns='item_id', values='rating')"
      ],
      "metadata": {
        "id": "ZeuTyN_vFLME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"User-Item Matrix:\\n\", user_item_matrix)"
      ],
      "metadata": {
        "id": "U8Y994DvIGsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill NaN with 0\n",
        "user_item_matrix = user_item_matrix.fillna(0)"
      ],
      "metadata": {
        "id": "hEH8PC25FNiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"User-Item Matrix with NaN filled with 0:\\n\", user_item_matrix)"
      ],
      "metadata": {
        "id": "h8W3z-OwIjxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute cosine similarity\n",
        "similarity_matrix = cosine_similarity(user_item_matrix)\n",
        "\n",
        "print(\"User-User Similarity Matrix:\\n\", similarity_matrix)"
      ],
      "metadata": {
        "id": "JJLYjibXFP_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommend items to user 1\n",
        "user_index = 0\n",
        "user_similarities = similarity_matrix[user_index]\n",
        "similar_users = user_similarities.argsort()[::-1][1:]  # exclude the user itself\n",
        "\n",
        "recommended_items = user_item_matrix.iloc[similar_users].mean(axis=0)\n",
        "recommended_items = recommended_items.sort_values(ascending=False)\n",
        "print(\"Recommended items for user 1:\\n\", recommended_items)"
      ],
      "metadata": {
        "id": "U2Tk6SxWFSqj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}