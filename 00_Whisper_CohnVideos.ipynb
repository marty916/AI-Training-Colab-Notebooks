{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1pmDnSNS8GN3KqatzCUjH605ome1sUZj3",
      "authorship_tag": "ABX9TyPsvJr0vzWFReUzPkkN2Onu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marty916/AI-Training-Colab-Notebooks/blob/main/00_Whisper_CohnVideos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 01: Download audo files using pytube"
      ],
      "metadata": {
        "id": "CqpbCyIVB2YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken openai"
      ],
      "metadata": {
        "id": "Mujf20Jc3jQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scrapetube"
      ],
      "metadata": {
        "id": "Rc0fQjTuu-kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-hMsbWcWTC7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use scrapetube to get all videoId(s) as a workaround to pytube bug in Channel"
      ],
      "metadata": {
        "id": "dsORqLbiyGrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scrapetube\n",
        "channel_Id = \"UCggngXyZiQtd_yAZbIFWz2A\" # LeadingAgile\n",
        "print(channel_Id)\n",
        "videos = scrapetube.get_channel(channel_Id)\n",
        "print(len(videos))\n",
        "#create a dictionary of metadata - videos is a generator and doesn't persist\n",
        "videos_metadata_dict = {}\n",
        "\n",
        "for video in videos:\n",
        "    video_id = video['videoId']\n",
        "\n",
        "    # Extract thumbnails\n",
        "    thumbnail_list = []\n",
        "    for thumb in video['thumbnail']['thumbnails']:\n",
        "        thumbnail_list.append({\n",
        "            'url': thumb['url'],\n",
        "            'width': thumb.get('width', None),\n",
        "            'height': thumb.get('height', None)\n",
        "        })\n",
        "\n",
        "    # Extract title\n",
        "    title_text = ''\n",
        "    if 'runs' in video['title']:\n",
        "        for run in video['title']['runs']:\n",
        "            title_text += run['text']\n",
        "\n",
        "    # Extract description snippet\n",
        "    description_text = ''\n",
        "    if 'runs' in video['descriptionSnippet']:\n",
        "        for run in video['descriptionSnippet']['runs']:\n",
        "            description_text += run['text']\n",
        "\n",
        "    videos_metadata_dict[video_id] = {\n",
        "        'videoId': video_id,\n",
        "        'channelId': channel_Id,\n",
        "        'thumbnail': {'thumbnails': thumbnail_list},\n",
        "        'title': title_text,\n",
        "        'descriptionSnippet': description_text,\n",
        "        'publishedTimeText': video['publishedTimeText']['simpleText'],\n",
        "        'lengthText': video['lengthText']['simpleText'],\n",
        "        'viewCountText': video['viewCountText']['simpleText']\n",
        "    }\n"
      ],
      "metadata": {
        "id": "ORnsXrQbvHaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install pytube from github to make sure you have the latest version. YouTube  API changes alot so this needs to stay current"
      ],
      "metadata": {
        "id": "7qUAsh0UyWGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/pytube/pytube"
      ],
      "metadata": {
        "id": "FdhnA2ObnYC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Mount your Google Drive in Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Install pytube fix for Channels (backlevels pytube - not good)\n",
        "# !pip install git+https://github.com/pishiko/pytube.git@42a7d8322dd7749a9e950baf6860d115bbeaedfc\n",
        "\n",
        "from pytube import YouTube, Channel\n",
        "from pytube.exceptions import RegexMatchError\n"
      ],
      "metadata": {
        "id": "YH-cW6yYCrEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. For each video, download the audio-only stream and save to your Google Drive\n",
        "# Define the save path\n",
        "save_path = \"/content/drive/MyDrive/LeadingAgileYTAudio\"\n",
        "ytvideo_path = 'https://youtube.com/watch?v='\n",
        "videos = scrapetube.get_channel(\"UCggngXyZiQtd_yAZbIFWz2A\")\n",
        "for video in videos:\n",
        "    video_url = ytvideo_path + video['videoId']\n",
        "    print (video_url)\n",
        "    try:\n",
        "        yt = YouTube(video_url)\n",
        "        print (yt.video_id)\n",
        "        # Get the audio-only stream\n",
        "        audio_files = yt.streams.filter(only_audio=True)\n",
        "        print (audio_files)\n",
        "\n",
        "\n",
        "        itag = None\n",
        "        for audio_file in audio_files:\n",
        "          print (audio_file.mime_type)\n",
        "          if audio_file.mime_type == 'audio/mp4':\n",
        "            itag = audio_file.itag\n",
        "            break\n",
        "\n",
        "        if itag is None:\n",
        "          print(f\"No audio-only stream found for '{video_url}'\")\n",
        "          continue\n",
        "\n",
        "        # Download and save the audio stream as mp3\n",
        "        print (itag)\n",
        "        stream =  yt.streams.get_by_itag(itag)\n",
        "\n",
        "        stream.download(output_path=save_path, filename=f\"{yt.video_id}.mp3\")\n",
        "\n",
        "    except RegexMatchError:\n",
        "        print(f\"RegexMatchError for '{video_url}'\")\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"Error for '{video_url}': {e}\")\n",
        "        continue"
      ],
      "metadata": {
        "id": "81lKvFOKswug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 02: Install whisper and ffmpeg (this works on colab A100)"
      ],
      "metadata": {
        "id": "NAlsSf9KB-lm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGdqj0ig1_aa"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "id": "ZFIxo2bv3CjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import torch\n",
        "# if you have access to a GPU use it\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "model = whisper.load_model(\"large\").to(device)\n"
      ],
      "metadata": {
        "id": "RGlORmw05TQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "# get list of MP3 audio files\n",
        "save_path = \"/content/drive/MyDrive/LeadingAgileYTAudio\"\n",
        "paths = [str(x) for x in (Path(save_path).glob('*.mp3'))]\n",
        "print(len(paths))\n",
        "print(paths[:5])\n"
      ],
      "metadata": {
        "id": "w0JOUrf263va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  debug line - just shows we're getting the videoId from the path\n",
        "paths[0].split('/')[-1][:-4]\n"
      ],
      "metadata": {
        "id": "xjzAIZu09JGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.cuda.memory import reset_accumulated_memory_stats\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "\n",
        "# set window (length of text chunk) and stride\n",
        "window = 1\n",
        "stride = 1  # smaller stride creates overlap\n",
        "\n",
        "data = []\n",
        "results = []\n",
        "\n",
        "with open(save_path + \"transcription.jsonl\", \"w\", encoding=\"utf-8\") as fp:\n",
        "  for i, path in enumerate(tqdm(paths)):\n",
        "    _id = path.split('/')[-1][:-4]\n",
        "    # transcribe to get speech-to-text\n",
        "    result = model.transcribe(path)\n",
        "    segments = result['segments']\n",
        "\n",
        "    # get the video metadata\n",
        "    video_metadata = videos_metadata_dict[_id]\n",
        "    for j in range(0, len(segments), stride):\n",
        "      j_end = min(j + window, len(segments)-1)\n",
        "      text = ''.join([x[\"text\"] for x in segments[j:j_end]])\n",
        "      start = segments[j][\"start\"]\n",
        "      end = segments[j_end][\"end\"]\n",
        "      row_id = f\"{_id}-t{segments[j]['start']}\"\n",
        "      meta = {\n",
        "        **video_metadata,\n",
        "        **{\n",
        "            \"id\": row_id,\n",
        "            \"text\": text.strip(),\n",
        "            \"start\": start,\n",
        "            \"end\": end\n",
        "          }\n",
        "      }\n",
        "      # add results to data list\n",
        "      data.append(meta)\n",
        "      json.dump(meta, fp)\n",
        "      fp.write('\\n')\n"
      ],
      "metadata": {
        "id": "R_Qs-20W8COQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(segments))\n"
      ],
      "metadata": {
        "id": "zUFWygFS_85Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HuXTKfYIHp01"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}