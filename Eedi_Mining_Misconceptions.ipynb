{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAX1/qePGWakoc13+QMrGh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marty916/AI-Training-Colab-Notebooks/blob/main/Eedi_Mining_Misconceptions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFllUWsxq0UU"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers sentence-transformers datasets\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses, util\n",
        "from sentence_transformers import SentencesDataset\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import logging\n",
        "import re\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "misconception_df = pd.read_csv('misconception_mapping.csv')\n",
        "sample_submission_df = pd.read_csv('sample_submission.csv')\n"
      ],
      "metadata": {
        "id": "i45Qp3FArI3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data cleaning and preprocessing\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess the text by replacing mathematical symbols and handling special characters.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The text to preprocess.\n",
        "\n",
        "    Returns:\n",
        "    str: The preprocessed text.\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return ''\n",
        "    # Replace mathematical symbols with words\n",
        "    text = re.sub(r'÷', ' division ', text)\n",
        "    text = re.sub(r'×', ' multiplication ', text)\n",
        "    text = re.sub(r'−', ' minus ', text)\n",
        "    text = re.sub(r'√', ' square root ', text)\n",
        "    text = re.sub(r'π', ' pi ', text)\n",
        "    text = re.sub(r'∠', ' angle ', text)\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "# Apply preprocessing to train and test data\n",
        "for df in [train_df, test_df]:\n",
        "    df.fillna('', inplace=True)\n",
        "    df['QuestionText'] = df['QuestionText'].apply(preprocess_text)\n",
        "    for option in ['A', 'B', 'C', 'D']:\n",
        "        df[f'Answer{option}Text'] = df[f'Answer{option}Text'].apply(preprocess_text)\n",
        "    df['ConstructName'] = df['ConstructName'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "6H6KeJIPrL46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_distractors(df, is_train=True):\n",
        "    \"\"\"\n",
        "    Extract distractors from the DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    df (pd.DataFrame): DataFrame containing question data.\n",
        "    is_train (bool): Flag indicating if the DataFrame is training data.\n",
        "\n",
        "    Returns:\n",
        "    pd.DataFrame: DataFrame with distractor information.\n",
        "    \"\"\"\n",
        "    distractors = []\n",
        "    for idx, row in df.iterrows():\n",
        "        correct_answer = row['CorrectAnswer']\n",
        "        for option in ['A', 'B', 'C', 'D']:\n",
        "            if option != correct_answer:\n",
        "                distractor = {\n",
        "                    'QuestionId': row['QuestionId'],\n",
        "                    'AnswerOption': option,\n",
        "                    'AnswerText': row[f'Answer{option}Text'],\n",
        "                    'QuestionText': row['QuestionText'],\n",
        "                    'ConstructName': row['ConstructName'],\n",
        "                    'SubjectName': row['SubjectName']\n",
        "                }\n",
        "                if is_train:\n",
        "                    distractor['MisconceptionId'] = row.get(f'Misconception{option}Id', None)\n",
        "                distractors.append(distractor)\n",
        "    return pd.DataFrame(distractors)\n",
        "\n",
        "# Prepare distractor data for training and testing\n",
        "train_distractors = get_distractors(train_df, is_train=True)\n",
        "test_distractors = get_distractors(test_df, is_train=False)\n"
      ],
      "metadata": {
        "id": "keuKF46jrTAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare misconception texts\n",
        "misconception_df['MisconceptionText'] = misconception_df['MisconceptionName'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "FJNpPHmIrXvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained sentence transformer model\n",
        "# Consider using a domain-specific model if available\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')  # Set device to CPU\n",
        "\n",
        "# Prepare training data for supervised fine-tuning\n",
        "train_distractors['CombinedText'] = (\n",
        "    train_distractors['QuestionText'] + ' Answer: ' +\n",
        "    train_distractors['AnswerText'] + ' Construct: ' +\n",
        "    train_distractors['ConstructName'] + ' Subject: ' +\n",
        "    train_distractors['SubjectName']\n",
        ")\n",
        "train_texts = train_distractors['CombinedText'].tolist()\n",
        "# Convert 'MisconceptionId' to numeric, coerce invalid values to NaN, and then to 0\n",
        "train_labels = pd.to_numeric(train_distractors['MisconceptionId'], errors='coerce').fillna(0).astype(int).tolist()\n",
        "\n",
        "# Create InputExamples for training\n",
        "train_examples = [\n",
        "    InputExample(texts=[text, misconception_df.loc[misconception_df['MisconceptionId'] == label, 'MisconceptionText'].values[0]],\n",
        "                 label=1.0)\n",
        "    for text, label in zip(train_texts, train_labels)\n",
        "]\n",
        "\n",
        "# Negative samples for contrastive learning\n",
        "negative_examples = []\n",
        "for text in train_texts:\n",
        "    negative_misconceptions = misconception_df.sample(n=3)['MisconceptionText'].tolist()\n",
        "    for neg_mis in negative_misconceptions:\n",
        "        negative_examples.append(InputExample(texts=[text, neg_mis], label=0.0))\n",
        "\n",
        "# Combine positive and negative examples\n",
        "train_examples.extend(negative_examples)\n",
        "\n",
        "# DataLoader for training\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
        "\n",
        "# Loss function\n",
        "train_loss = losses.CosineSimilarityLoss(model)\n"
      ],
      "metadata": {
        "id": "1yx6xe1NraK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune the model on training data\n",
        "num_epochs = 1  # Adjust as needed\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    epochs=num_epochs,\n",
        "    warmup_steps=int(len(train_dataloader) * num_epochs * 0.1)\n",
        ")\n"
      ],
      "metadata": {
        "id": "JHMF4Mb3si9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for misconceptions\n",
        "misconception_texts = misconception_df['MisconceptionText'].tolist()\n",
        "misconception_embeddings = model.encode(misconception_texts, convert_to_tensor=True)\n"
      ],
      "metadata": {
        "id": "cyDLVumYF5Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare distractor texts for test data\n",
        "test_distractors['CombinedText'] = (\n",
        "    test_distractors['QuestionText'] + ' Answer: ' +\n",
        "    test_distractors['AnswerText'] + ' Construct: ' +\n",
        "    test_distractors['ConstructName'] + ' Subject: ' +\n",
        "    test_distractors['SubjectName']\n",
        ")\n",
        "test_texts = test_distractors['CombinedText'].tolist()\n",
        "\n",
        "# Generate embeddings for distractors\n",
        "distractor_embeddings = model.encode(test_texts, convert_to_tensor=True)\n"
      ],
      "metadata": {
        "id": "G38IgLVUGFLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute similarity scores in batches to manage memory\n",
        "batch_size = 100\n",
        "all_top_k_misconception_ids = []\n",
        "top_k = 25\n",
        "\n",
        "for i in range(0, len(distractor_embeddings), batch_size):\n",
        "    batch_embeddings = distractor_embeddings[i:i+batch_size]\n",
        "    similarity_scores = util.cos_sim(batch_embeddings, misconception_embeddings)\n",
        "    top_k_values, top_k_indices = torch.topk(similarity_scores, k=top_k, dim=1)\n",
        "    misconception_ids_array = misconception_df['MisconceptionId'].values\n",
        "    batch_top_k_misconception_ids = misconception_ids_array[top_k_indices.cpu().numpy()]\n",
        "    all_top_k_misconception_ids.extend(batch_top_k_misconception_ids)\n",
        "\n",
        "    # Free memory\n",
        "    del batch_embeddings, similarity_scores, top_k_values, top_k_indices\n",
        "\n",
        "# Ensure that we have predictions for all distractors\n",
        "assert len(all_top_k_misconception_ids) == len(test_distractors), \"Mismatch in prediction lengths.\"\n"
      ],
      "metadata": {
        "id": "oQPZZfixGKft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare QuestionId_Answer\n",
        "test_distractors['QuestionId_Answer'] = test_distractors['QuestionId'].astype(str) + '_' + test_distractors['AnswerOption']\n",
        "\n",
        "# Prepare MisconceptionId predictions\n",
        "test_distractors['MisconceptionId'] = [\n",
        "    ' '.join(map(str, ids)) for ids in all_top_k_misconception_ids\n",
        "]\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission_df = test_distractors[['QuestionId_Answer', 'MisconceptionId']]\n",
        "\n",
        "# Ensure that submission_df has all required rows from sample_submission.csv\n",
        "submission_df = sample_submission_df[['QuestionId_Answer']].merge(submission_df, on='QuestionId_Answer', how='left')\n",
        "\n",
        "# Handle missing MisconceptionId predictions\n",
        "if submission_df['MisconceptionId'].isnull().any():\n",
        "    # Get most frequent MisconceptionIds from training data\n",
        "    most_common_misconceptions = train_distractors['MisconceptionId'].value_counts().index[:25].tolist()\n",
        "    default_misconceptions = ' '.join(map(str, most_common_misconceptions))\n",
        "    submission_df['MisconceptionId'].fillna(default_misconceptions, inplace=True)\n",
        "\n",
        "# Validate submission format\n",
        "assert len(submission_df) == len(sample_submission_df), \"Submission file has incorrect number of rows.\"\n",
        "missing_ids = set(sample_submission_df['QuestionId_Answer']) - set(submission_df['QuestionId_Answer'])\n",
        "assert len(missing_ids) == 0, f\"Missing QuestionId_Answer entries: {missing_ids}\"\n"
      ],
      "metadata": {
        "id": "gbkXkTnHGRw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save submission file\n",
        "submission_df.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "id": "cOIRM1uOGV5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Only run this to download the model for Kaggle"
      ],
      "metadata": {
        "id": "uUV2aMQRwV_E"
      }
    }
  ]
}